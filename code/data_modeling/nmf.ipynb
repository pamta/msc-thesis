{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('env')",
   "metadata": {
    "interpreter": {
     "hash": "9da78ff3513faed79987464be42cd2d368fc5cc0cc8750796d4e667a76f20c05"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import silhouette_mod\n",
    "import utils\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.cluster import KMeans, DBSCAN, OPTICS\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.leer_dpto('SOAD')\n",
    "df_menus = utils.leer_menus_labels(\"modified-menus\", 1)\n",
    "df_menus = df_menus[df_menus[\"prospecto\"] == 1]\n",
    "df_menus.drop_duplicates(subset=\"OracionLematizada\", keep=\"first\", inplace=True)\n",
    "df_menus['idx'] = [i for i in range(0, len(df_menus))]\n",
    "print(f\"There are {len(df)} items in df\")\n",
    "print(f\"There are {len(df_menus)} items in df_menus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DF = 2\n",
    "MAX_DF = 0.95\n",
    "MAX_FEATURES = 500\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,3), min_df=MIN_DF, max_df=MAX_DF, max_features=MAX_FEATURES)\n",
    "X_text = tfidf.fit_transform(df['OracionLematizada'].values)\n",
    "print(f\"dtm shape: {X_text.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DF = 2\n",
    "MAX_DF = 0.95\n",
    "MAX_FEATURES = 500\n",
    "#tfidf = TfidfVectorizer(ngram_range=(1,3), min_df=MIN_DF, max_df=MAX_DF, max_features=MAX_FEATURES)\n",
    "cvtext = CountVectorizer(min_df=MIN_DF, max_df=MAX_DF, max_features=MAX_FEATURES)\n",
    "X_text = cvtext.fit_transform(df['OracionLematizada'].values)\n",
    "print(f\"dtm shape: {X_text.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_svd = True\n",
    "expected_variance = 0.90\n",
    "\n",
    "if use_svd:\n",
    "    full_svd = TruncatedSVD(n_components=X_text.shape[1]-1)\n",
    "    X_full_svd = full_svd.fit(X_text)\n",
    "    full_svd_ratios = full_svd.explained_variance_ratio_\n",
    "    n_components = utils.select_n_components(full_svd_ratios, expected_variance)\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    lsa = make_pipeline(svd, normalizer)\n",
    "    X_2d = lsa.fit_transform(X_text)\n",
    "\n",
    "    print(f\"original components: {X_text.shape[1]-1}\")\n",
    "    print(f\"original ratio: {round(sum(full_svd_ratios), 4)}\")\n",
    "    print(f\"expected variance: {expected_variance}\")\n",
    "    print(f\"X_2d shape: {X_2d.shape}\")\n",
    "    print(f\"X_2d variance: {round(sum(svd.explained_variance_ratio_), 4)}\")\n",
    "else:\n",
    "    X_2d = X_text.copy()\n",
    "    print(f\"X_2d shape: {X_2d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "n_components = 10\n",
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_words(model, feature_names, n_top_words, title):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(60, 25), sharex=True)\n",
    "    axes = axes.flatten()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_features = [feature_names[i] for i in top_features_ind]\n",
    "        weights = topic[top_features_ind]\n",
    "\n",
    "        ax = axes[topic_idx]\n",
    "        ax.barh(top_features, weights, height=0.7)\n",
    "        ax.set_title(f'Topic {topic_idx +1}',\n",
    "                     fontdict={'fontsize': 30})\n",
    "        ax.invert_yaxis()\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        for i in 'top right left'.split():\n",
    "            ax.spines[i].set_visible(False)\n",
    "        fig.suptitle(title, fontsize=40)\n",
    "\n",
    "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=n_components, random_state=1, alpha=.1, l1_ratio=.5).fit(X_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf.get_feature_names()\n",
    "#feature_names = cvtext.get_feature_names()\n",
    "plot_top_words(nmf, feature_names, n_top_words, 'Topics in NMF model (Frobenius norm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsVStopics = pd.DataFrame(nmf.transform(X_text), columns=[\"Topic\"+str(i+1) for i in range(10)])\n",
    "print(\"Created a (%dx%d) document-topic matrix.\" % (docsVStopics.shape[0], docsVStopics.shape[1]))\n",
    "most_likely_topics = docsVStopics.idxmax(axis=1)\n",
    "most_likely_topics.groupby(most_likely_topics).count()"
   ]
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=n_components, random_state=1, beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1, l1_ratio=.5).fit(X_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf.get_feature_names()\n",
    "plot_top_words(nmf, feature_names, n_top_words, 'Topics in NMF model (generalized Kullback-Leibler divergence)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsVStopics = pd.DataFrame(nmf.transform(X_text), columns=[\"Topic\"+str(i+1) for i in range(10)])\n",
    "print(\"Created a (%dx%d) document-topic matrix.\" % (docsVStopics.shape[0], docsVStopics.shape[1]))\n",
    "most_likely_topics = docsVStopics.idxmax(axis=1)\n",
    "most_likely_topics.groupby(most_likely_topics).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}