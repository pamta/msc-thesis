{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd09da78ff3513faed79987464be42cd2d368fc5cc0cc8750796d4e667a76f20c05",
   "display_name": "Python 3.8.8 64-bit ('env': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "9da78ff3513faed79987464be42cd2d368fc5cc0cc8750796d4e667a76f20c05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Clustering\n",
    "## Import de librerias"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import silhouette_mod\n",
    "import utils\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.cluster import KMeans, DBSCAN, OPTICS\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "source": [
    "## Lectura de dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.leer_dpto('SOAD')\n",
    "df_menus = utils.leer_menus_labels(\"modified-menus\", 1)\n",
    "df_menus = df_menus[df_menus[\"prospecto\"] == 1]\n",
    "df_menus.drop_duplicates(subset=\"OracionLematizada\", keep=\"first\", inplace=True)\n",
    "df_menus['idx'] = [i for i in range(0, len(df_menus))]\n",
    "print(f\"There are {len(df)} items in df\")\n",
    "print(f\"There are {len(df_menus)} items in df_menus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "## Vectorize"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DF = 2\n",
    "MAX_DF = 0.95\n",
    "MAX_FEATURES = 500\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,3), min_df=MIN_DF, max_df=MAX_DF, max_features=MAX_FEATURES)\n",
    "X_text = tfidf.fit_transform(df['OracionLematizada'].values)\n",
    "print(f\"dtm shape: {X_text.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DF = 0.01\n",
    "MAX_DF = 0.95\n",
    "MAX_FEATURES = 500\n",
    "#tfidf = TfidfVectorizer(ngram_range=(1,3), min_df=MIN_DF, max_df=MAX_DF, max_features=MAX_FEATURES)\n",
    "#cvtext = CountVectorizer(min_df=MIN_DF, max_df=MAX_DF, max_features=MAX_FEATURES)\n",
    "cvtext = CountVectorizer()\n",
    "X_text = cvtext.fit_transform(df['Cuerpo'].values)\n",
    "print(f\"dtm shape: {X_text.shape}\")"
   ]
  },
  {
   "source": [
    "## Dimension reduction using TruncatedSVD"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We create a full svd in order to be removing a feature one by one"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_svd = True\n",
    "expected_variance = 0.90\n",
    "\n",
    "if use_svd:\n",
    "    full_svd = TruncatedSVD(n_components=X_text.shape[1]-1)\n",
    "    X_full_svd = full_svd.fit(X_text)\n",
    "    full_svd_ratios = full_svd.explained_variance_ratio_\n",
    "    n_components = utils.select_n_components(full_svd_ratios, expected_variance)\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    lsa = make_pipeline(svd, normalizer)\n",
    "    X_2d = lsa.fit_transform(X_text)\n",
    "\n",
    "    print(f\"original components: {X_text.shape[1]-1}\")\n",
    "    print(f\"original ratio: {round(sum(full_svd_ratios), 4)}\")\n",
    "    print(f\"expected variance: {expected_variance}\")\n",
    "    print(f\"X_2d shape: {X_2d.shape}\")\n",
    "    print(f\"X_2d variance: {round(sum(svd.explained_variance_ratio_), 4)}\")\n",
    "else:\n",
    "    X_2d = X_text.copy()\n",
    "    print(f\"X_2d shape: {X_2d.shape}\")"
   ]
  },
  {
   "source": [
    "## KMEANS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Silhouette visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_elbow = False\n",
    "\n",
    "if plot_elbow:\n",
    "    clusters_range = range(50, 1050, 50)\n",
    "    visualizer = silhouette_mod.KElbowVisualizer(KMeans(random_state=42), metric='silhouette', k=clusters_range)\n",
    "    visualizer.fit(X_2d)\n",
    "    visualizer.poof()"
   ]
  },
  {
   "source": [
    "### Clustering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_clusters_kmeans = 100\n",
    "kmeans = KMeans(n_clusters=n_clusters_kmeans, random_state=42)\n",
    "intents = kmeans.fit_transform(X_2d)\n",
    "df['cluster'] = kmeans.labels_\n",
    "print(f\"silhouette score: {silhouette_score(X_2d, kmeans.labels_, sample_size=1000, random_state=42)}\")"
   ]
  },
  {
   "source": [
    "### Represenative centroids of clusters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representative_intents_idx = np.argmin(intents, axis=0)\n",
    "representative_intents = X_text[representative_intents_idx]\n",
    "representative = df.iloc[representative_intents_idx].sort_values(by=\"cluster\").copy()"
   ]
  },
  {
   "source": [
    "### Text recommendation message to chatbot option (representative dataframe)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "k = 1\n",
    "list_documents = df_menus['OracionLematizada'].values\n",
    "list_query = representative['OracionLematizada'].values\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
    "docs_tfidf = vectorizer.fit_transform(list_documents)\n",
    "index_top_k, value_top_k = utils.get_tf_idf_query_similarity(vectorizer, docs_tfidf, list_query, k)\n",
    "# case k = 1\n",
    "if k == 1:\n",
    "    index_top_k = [idx[0] for idx in index_top_k]\n",
    "    value_top_k = [val[0] for val in value_top_k]\n",
    "\n",
    "recommendation_df = pd.DataFrame()\n",
    "recommendation_df['message'] = representative['OracionLematizada'].values\n",
    "recommendation_df['cluster'] = representative['cluster'].values\n",
    "index_top_k_list = [idx if val > 0 else -1 for idx, val in zip(index_top_k, value_top_k)]\n",
    "recommendation_df['index_top_k'] = index_top_k_list\n",
    "value_top_k_list = [val if val > 0 else 0 for val in value_top_k]\n",
    "recommendation_df['value_top_k'] = value_top_k_list\n",
    "recommendation_df['menu_top_k'] = [df_menus[df_menus['idx'] == idx]['OracionLematizada'].values[0] if idx >= 0 else \"-NA-\" for idx in recommendation_df['index_top_k']]\n",
    "recommendation_df.to_csv(\"recommendation_representative.csv\", index=False)\n",
    "recommendation_df.head()"
   ]
  },
  {
   "source": [
    "### Stats for representative messages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = recommendation_df.groupby('index_top_k').mean()['value_top_k']\n",
    "counts = recommendation_df.groupby('index_top_k').count()['cluster']\n",
    "idxs = recommendation_df.groupby('index_top_k').count().reset_index()['index_top_k'].values\n",
    "\n",
    "idxs_cons = []\n",
    "means_cons = []\n",
    "counts_cons = []\n",
    "for i in range(-1, len(df_menus)):\n",
    "    if i in idxs:\n",
    "        idxs_cons.append(i)\n",
    "        means_cons.append(means[i])\n",
    "        counts_cons.append(counts[i])\n",
    "    else:\n",
    "        idxs_cons.append(i)\n",
    "        means_cons.append(0)\n",
    "        counts_cons.append(0)\n",
    "df_representative = pd.DataFrame(list(zip(idxs_cons, counts_cons, means_cons)), columns=['idx', 'count', 'mean'])\n",
    "df_representative.to_csv(\"recommendation_representative_stats.csv\", index=False)\n",
    "df_representative"
   ]
  },
  {
   "source": [
    "### Text recommendation message to chatbot option (prospect dataframe)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "k = 1\n",
    "list_documents = df_menus['OracionLematizada'].values\n",
    "list_query = df['OracionLematizada'].values\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
    "docs_tfidf = vectorizer.fit_transform(list_documents)\n",
    "index_top_k, value_top_k = utils.get_tf_idf_query_similarity(vectorizer, docs_tfidf, list_query, k)\n",
    "# case k = 1\n",
    "if k == 1:\n",
    "    index_top_k = [idx[0] for idx in index_top_k]\n",
    "    value_top_k = [val[0] for val in value_top_k]\n",
    "\n",
    "recommendation_df = pd.DataFrame()\n",
    "recommendation_df['message'] = df['OracionLematizada'].values\n",
    "recommendation_df['cluster'] = df['cluster'].values\n",
    "index_top_k_list = [idx if val > 0 else -1 for idx, val in zip(index_top_k, value_top_k)]\n",
    "recommendation_df['index_top_k'] = index_top_k_list\n",
    "value_top_k_list = [val if val > 0 else 0 for val in value_top_k]\n",
    "recommendation_df['value_top_k'] = value_top_k_list\n",
    "recommendation_df['menu_top_k'] = [df_menus[df_menus['idx'] == idx]['OracionLematizada'].values[0] if idx >= 0 else \"-NA-\" for idx in recommendation_df['index_top_k']]\n",
    "recommendation_df.columns = ['message', 'cluster', 'idx', 'score', 'menu_message']\n",
    "recommendation_df.to_csv(\"recommendation_whole.csv\", index=False)\n",
    "recommendation_df.head()"
   ]
  },
  {
   "source": [
    "### Stats for whole messages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = recommendation_df.groupby(['cluster', 'idx']).mean().reset_index()\n",
    "grouped['count'] = recommendation_df.groupby(['cluster', 'idx']).count().reset_index()['score']\n",
    "\n",
    "grouped.to_csv(\"recommendation_whole_cluster_stats.csv\", index=False)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = recommendation_df.groupby('idx').mean()['score']\n",
    "counts = recommendation_df.groupby('idx').count()['cluster']\n",
    "idxs = recommendation_df.groupby('idx').count().reset_index()['idx'].values\n",
    "\n",
    "idxs_cons = []\n",
    "means_cons = []\n",
    "counts_cons = []\n",
    "for i in range(-1, len(df_menus)):\n",
    "    if i in idxs:\n",
    "        idxs_cons.append(i)\n",
    "        means_cons.append(means[i])\n",
    "        counts_cons.append(counts[i])\n",
    "    else:\n",
    "        idxs_cons.append(i)\n",
    "        means_cons.append(0)\n",
    "        counts_cons.append(0)\n",
    "df_whole = pd.DataFrame(list(zip(idxs_cons, counts_cons, means_cons)), columns=['idx', 'count', 'mean'])\n",
    "df_whole.to_csv(\"recommendation_whole_stats.csv\", index=False)\n",
    "df_whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_menus[df_menus['idx'].isin(df_whole[df_whole['count'] <= 5]['idx'].values)]"
   ]
  },
  {
   "source": [
    "## Analysis on Adjusted Rand Index of K Means against estimated true labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "list_score = []\n",
    "list_arr = []\n",
    "list_count = []\n",
    "#list_score.append(0)\n",
    "#list_arr.append(adjusted_rand_score(recommendation_df['cluster'], recommendation_df['idx']))\n",
    "#list_count.append(len(recommendation_df))\n",
    "for score in np.linspace(0, 0.8, 50):\n",
    "    list_score.append(score)\n",
    "    list_arr.append(adjusted_rand_score(recommendation_df[recommendation_df['score'] >= score]['cluster'], recommendation_df[recommendation_df['score'] >= score]['idx']))\n",
    "    list_count.append(len(recommendation_df[recommendation_df['score'] >= score]['cluster']))\n",
    "\n",
    "print(tabulate(pd.DataFrame(list(zip(list_score, list_arr, list_count)), columns=['score', 'adjrandind', 'count']), headers=['similarity score', 'adjrandind', 'count'], tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(20, 13)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel('Similarity Score', fontsize=18)\n",
    "plt.ylabel('AdjRandIndex', fontsize=16)\n",
    "df_to_plot = pd.DataFrame(list(zip(list_arr, list_score)), columns=['AdjRandIndex', 'Score'])\n",
    "sns.lineplot(data = df_to_plot, x='Score', y='AdjRandIndex', linewidth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_to_filter = round(0.0000001, 6)\n",
    "super_list = recommendation_df[recommendation_df['score'] > score_to_filter].copy()\n",
    "super_list_grouped = super_list.groupby('idx').count()[['cluster']]\n",
    "missing_list = [i for i in range(0, len(df_menus)) if i not in super_list_grouped.index.values]\n",
    "print(f\"similarityscore used for filtering: {score_to_filter}\")\n",
    "print(f\"elements in filtered list: {len(super_list)}\")\n",
    "print(f\"percentage of filtered elements from original dataframe: {round(len(super_list) / len(df) * 100, 6)}%\")\n",
    "print(f\"\")\n",
    "print(f\"missing indexes\")\n",
    "print(tabulate(pd.DataFrame(df_menus[df_menus['idx'].isin(missing_list)][['idx', 'TEXTO', 'OracionLematizada']], columns=['idx', 'TEXTO', 'OracionLematizada']), showindex=False, headers=['idx', 'texto', 'oracion lematizada'], tablefmt='pretty'))\n",
    "print(f\"\")\n",
    "print(f\"top 10 intents by count\")\n",
    "print(tabulate(super_list_grouped.sort_values(by=\"cluster\", ascending=False).join(df_menus.set_index('idx')).reset_index()[['idx', 'TEXTO', 'cluster']].head(10), showindex=False, headers=['idx', 'texto', 'count'], tablefmt='pretty'))\n",
    "print(f\"\")\n",
    "print(f\"brief comparison of clustered text to the intent\")\n",
    "print(tabulate(super_list.set_index('idx').join(df_menus.set_index('idx')).reset_index()[['idx', 'message', 'TEXTO']].sample(10), showindex=False, headers=['idx', 'texto prospecto', 'texto intent'], tablefmt='pretty'))"
   ]
  },
  {
   "source": [
    "Similarity cluster 1vs1 on intents"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- Hallar cuantos intents de los 54 se cubren bajo un cierto umbral de similitud\n",
    "- Denotar intents repetidos\n",
    "- Obtener un precision de # intents encontrados / 54 (total de intents)\n",
    "- Ver que se podria cambiar para mejorar"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cluster_analysis(\n",
    "    df, cluster_label, text_label, menus, tfidf, total, filter_zeros\n",
    "):\n",
    "    # MAIN FUNCTION\n",
    "    with tqdm(\n",
    "        total=total, bar_format=\"{bar}|{desc}{percentage:3.0f}% {r_bar}\", leave=False\n",
    "    ) as pbar:\n",
    "        list_cluster = []\n",
    "        list_intent = []\n",
    "        list_intent_text = []\n",
    "        list_mean = []\n",
    "        list_count = []\n",
    "        for cluster in range(0, total):\n",
    "            list_documents = menus[\"OracionLematizada\"].values\n",
    "            list_query = df[df[cluster_label] == cluster][text_label].values\n",
    "            docs_tfidf = tfidf.fit_transform(list_documents)\n",
    "            query_tfidf = tfidf.transform(list_query)\n",
    "\n",
    "            cosineSimilarities = cosine_similarity(docs_tfidf, query_tfidf)\n",
    "            list_intents_means = [np.mean(sims) for sims in cosineSimilarities]\n",
    "            list_cluster.append(cluster)\n",
    "            list_intent.append(np.argmax(list_intents_means))\n",
    "            list_intent_text.append(\n",
    "                menus[menus[\"idx\"] == np.argmax(list_intents_means)][\n",
    "                    \"OracionLematizada\"\n",
    "                ].values[0]\n",
    "            )\n",
    "            list_mean.append(np.max(list_intents_means))\n",
    "            list_count.append(len(list_query))\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    df_sim = pd.DataFrame(\n",
    "        list(zip(list_cluster, list_count, list_intent, list_intent_text, list_mean)),\n",
    "        columns=[\"cluster\", \"count\", \"intent\", \"intent text\", \"mean score\"],\n",
    "    )\n",
    "\n",
    "    # TABULATE\n",
    "    print(\"mean score on cluster argmax\")\n",
    "    print(\n",
    "        tabulate(\n",
    "            df_sim,\n",
    "            showindex=False,\n",
    "            headers=[\"cluster\", \"count\", \"intent\", \"intent text\", \"mean score\"],\n",
    "            tablefmt=\"pretty\",\n",
    "        )\n",
    "    )\n",
    "    print()\n",
    "\n",
    "    # PLOT AXES\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(20, 13)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.xlabel(\"cluster\", fontsize=18)\n",
    "    plt.ylabel(\"mean score\", fontsize=16)\n",
    "    df_to_plot = df_sim.copy()\n",
    "    ax = sns.barplot(data=df_to_plot, x=\"cluster\", y=\"mean score\", linewidth=3)\n",
    "    rango = range(0, total + 10, 10)\n",
    "    ax.set_xticks(rango)\n",
    "    for x in rango:\n",
    "        ax.axvline(x, linestyle=\"-\", color=\"#7f7f7f\", linewidth=0.5)\n",
    "    plt.show()\n",
    "\n",
    "    # PLOT HIST\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(20, 13)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.xlabel(\"cluster\", fontsize=18)\n",
    "    plt.ylabel(\"mean score\", fontsize=16)\n",
    "    ax = sns.histplot(data=df_sim, x=\"mean score\")\n",
    "    plt.show()\n",
    "\n",
    "    # PLOT HIST zoomed\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(20, 13)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.xlabel(\"cluster\", fontsize=18)\n",
    "    plt.ylabel(\"mean score\", fontsize=16)\n",
    "    ax = sns.histplot(data=df_sim[df_sim[\"mean score\"] > 0], x=\"mean score\")\n",
    "    plt.show()\n",
    "\n",
    "    # DF INFO\n",
    "    print()\n",
    "    print(\"DF INFO:\")\n",
    "    df_sim.info()\n",
    "    print(\"\")\n",
    "\n",
    "    return df_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1, 3))\n",
    "total = n_clusters_kmeans\n",
    "filter_zeros = False\n",
    "res = run_cluster_analysis(df, 'cluster', 'OracionLematizada', df_menus, tfidf, total, filter_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head()\n",
    "res.to_csv(\"res.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_intent = pd.Series(list(np.empty(len(df))))\n",
    "list_intent_text = pd.Series(list(np.empty(len(df))))\n",
    "\n",
    "for k in range(n_clusters_kmeans):\n",
    "    list_intent[df['cluster'] == k] = res[res['cluster'] == k]['intent'].values[0]\n",
    "    list_intent_text[df['cluster'] == k] = res[res['cluster'] == k]['intent text'].values[0]\n",
    "\n",
    "df['intent'] = list_intent\n",
    "df['intent text'] = list_intent_text\n",
    "df.head()\n",
    "df.to_csv(\"to_validate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ref = pd.read_csv(\"res_sample_sizes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "for k in range(n_clusters_kmeans):\n",
    "    temp = df[df['cluster'] == k].sample(n=sample_ref[sample_ref['cluster'] == k]['sample_80_10'].values[0])\n",
    "    temp['x'] = np.zeros(len(temp))\n",
    "    temp.to_csv(\"tf-idf-500-300/samples-per-k/\" + str(k) + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_threshold = []\n",
    "list_precision = []\n",
    "list_count = []\n",
    "list_count_binary = []\n",
    "for threshold in np.linspace(0, 1, 50):\n",
    "    val, count_sum, count_binary_sum, precision = utils.run_precision(res, df_menus, threshold, show_table=False)\n",
    "    list_threshold.append(val)\n",
    "    list_precision.append(precision)\n",
    "    list_count.append(count_sum)\n",
    "    list_count_binary.append(count_binary_sum)\n",
    "df_precision = pd.DataFrame(list(zip(list_threshold, list_precision, list_count, list_count_binary)), columns=['threshold', 'precision', 'sum count', 'binary count'])\n",
    "df_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = df.sample(n=383, random_state=42).index\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['intent_sim'] = -1 * len(df)\n",
    "df['intent_idx'] = -1 * len(df)\n",
    "df['intent_sim_overall'] = -1 * len(df)\n",
    "list_intents_means = []\n",
    "for k in range(n_clusters_kmeans):\n",
    "    list_query = df[df['cluster'] == k]['OracionLematizada'].values\n",
    "    docs_tfidf = tfidf.fit_transform(df_menus['OracionLematizada'].values)\n",
    "    query_tfidf = tfidf.transform(list_query)\n",
    "    cosineSimilarities = cosine_similarity(docs_tfidf, query_tfidf)\n",
    "    list_intents_means = [np.mean(sims) for sims in cosineSimilarities]\n",
    "    df.loc[df['cluster'] == k, 'intent_sim'] = [x for x in cosineSimilarities[np.argmax(list_intents_means)]]\n",
    "    df.loc[df['cluster'] == k, 'intent_idx'] = np.argmax(list_intents_means)\n",
    "    df.loc[df['cluster'] == k, 'intent_sim_overall'] = np.max(list_intents_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = df.iloc[samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation['validation'] = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(validation[validation['validation'] == 0].describe())\n",
    "display(validation[validation['validation'] == 1].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation[(validation['validation'] == 0) & (validation['intent_sim'] > 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "threshold = 0.383831\n",
    "measured = validation[validation['intent_sim'] > threshold]\n",
    "\n",
    "nmf = metrics.normalized_mutual_info_score(validation['intent_idx'].values.tolist(), list(text_propagated))\n",
    "amf = metrics.adjusted_mutual_info_score(validation['intent_idx'].values.tolist(), list(text_propagated))\n",
    "ars = metrics.adjusted_rand_score(validation['intent_idx'].values.tolist(), list(text_propagated))\n",
    "\n",
    "print(nmf)\n",
    "print(amf)\n",
    "print(ars)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le = le.fit(recommendation_df['similar_menu_label_index'].values.tolist())\n",
    "\n",
    "true = le.transform(recommendation_df['similar_menu_label_index'].values.tolist())\n",
    "pred = le.transform(list(text_propagated))\n",
    "accuracy = metrics.accuracy_score(true, pred)\n",
    "precision = metrics.precision_score(true, pred, average='weighted')\n",
    "recall = metrics.recall_score(true, pred, average='weighted')\n",
    "f1 = metrics.f1_score(true, pred, average='weighted')\n",
    "\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "source": [
    "# Hierarchical"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms\")\n",
    "dend = shc.dendrogram(shc.linkage(X_2d, method='ward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## DBSCAN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Application of algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SAMPLES = 10\n",
    "EPS = 0.075\n",
    "db = DBSCAN(min_samples=MIN_SAMPLES, eps = EPS, metric=\"cosine\").fit(X_2d)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "df['cluster_DBSCAN'] = labels\n",
    "df.to_csv(\"clustering_dbscan.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "menus = df_menus['OracionLematizada'].copy()\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 3))\n",
    "total = n_clusters_\n",
    "filter_zeros = False\n",
    "res = utils.run_cluster_analysis(df, 'cluster_DBSCAN', 'OracionLematizada', menus, tfidf, total, filter_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.05\n",
    "utils.run_precision(res, df_menus, threshold, show_table=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['cluster_DBSCAN'] == np.random.randint(low=0, high=n_clusters_)]"
   ]
  },
  {
   "source": [
    "---\n",
    "# END OF NOTEBOOK\n",
    "\n",
    "## STATS FOR CLUSTERING\n",
    "## KMEANS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"clustering_dbscan.csv\")\n",
    "df = df[['cluster', 'idx', 'score']]\n",
    "counts = df.groupby(['cluster', 'idx']).count()['score'].values\n",
    "means = df.groupby(['cluster', 'idx']).mean()['score'].values\n",
    "idxs = df.groupby(['cluster', 'idx']).mean().reset_index()['idx'].values\n",
    "clusters = df.groupby(['cluster', 'idx']).mean().reset_index()['cluster'].values\n",
    "df_stats = pd.DataFrame(list(zip(clusters, idxs, counts, means)), columns=['cluster', 'idx', 'count', 'mean'])\n",
    "df_stats.to_csv(\"clustering_kmeans_stats.csv\", index=False)\n",
    "df_stats.head()"
   ]
  },
  {
   "source": [
    "## DBSCAN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"clustering_dbscan.csv\")\n",
    "df = df[['cluster_DBSCAN', 'idx', 'score']]\n",
    "counts = df.groupby(['cluster_DBSCAN', 'idx']).count()['score'].values\n",
    "means = df.groupby(['cluster_DBSCAN', 'idx']).mean()['score'].values\n",
    "idxs = df.groupby(['cluster_DBSCAN', 'idx']).mean().reset_index()['idx'].values\n",
    "clusters = df.groupby(['cluster_DBSCAN', 'idx']).mean().reset_index()['cluster'].values\n",
    "df_stats = pd.DataFrame(list(zip(clusters, idxs, counts, means)), columns=['cluster_DBSCAN', 'idx', 'count', 'mean'])\n",
    "df_stats.to_csv(\"clustering_dbscan_stats.csv\", index=False)\n",
    "df_stats.head()"
   ]
  },
  {
   "source": [
    "---\n",
    "# Experimento Spacy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('es_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_menus = list(nlp.pipe(df_menus['OracionLematizada'].values))\n",
    "with tqdm(total = len(df), bar_format='{bar}|{desc}{percentage:3.0f}% {r_bar}', leave=False) as pbar:\n",
    "    list_idx = []\n",
    "    list_msg = []\n",
    "    list_argmax = []\n",
    "    list_rec = []\n",
    "    list_max = []\n",
    "    idx = 0\n",
    "    for doc1 in nlp.pipe(df['OracionLematizada'].values):\n",
    "        list2 = []\n",
    "        for idx2, doc2 in enumerate(doc_menus):\n",
    "            list2.append(doc1.similarity(doc2))\n",
    "        list2 = np.array(list2)\n",
    "        argmax_sim = np.argmax(list2)\n",
    "        max_sim = np.max(list2)\n",
    "        list_idx.append(idx)\n",
    "        list_msg.append(doc1)\n",
    "        list_argmax.append(argmax_sim)\n",
    "        list_rec.append(df_menus.iloc[argmax_sim]['OracionLematizada'])\n",
    "        list_max.append(max_sim)\n",
    "        idx += 1\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_df = pd.DataFrame()\n",
    "spacy_df['list_idx'] = list_idx\n",
    "spacy_df['list_msg'] = list_msg\n",
    "spacy_df['list_argmax'] = list_argmax\n",
    "spacy_df['list_rec'] = list_rec\n",
    "spacy_df['list_max'] = list_max\n",
    "spacy_df['cos_idx'] = rec_df['idx']\n",
    "spacy_df['cos_rec'] = rec_df['recommendation']\n",
    "\n",
    "spacy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_df['list_max'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_df[spacy_df['list_max'] > 0.7].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}