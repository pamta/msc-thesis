{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('env')",
   "metadata": {
    "interpreter": {
     "hash": "9da78ff3513faed79987464be42cd2d368fc5cc0cc8750796d4e667a76f20c05"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"menus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preposiciones = [\n",
    "        \"a\",\n",
    "        \"e\",\n",
    "        \"u\",\n",
    "        \"durante\",\n",
    "        \"seg√∫n\",\n",
    "        \"ante\",\n",
    "        \"en\",\n",
    "        \"sin\",\n",
    "        \"bajo\",\n",
    "        \"entre\",\n",
    "        \"so\",\n",
    "        \"cabe\",\n",
    "        \"hacia\",\n",
    "        \"sobre\",\n",
    "        \"con\",\n",
    "        \"hasta\",\n",
    "        \"tras\",\n",
    "        \"contra\",\n",
    "        \"mediante\",\n",
    "        \"versus\",\n",
    "        \"de\",\n",
    "        \"para\",\n",
    "        \"via\",\n",
    "        \"desde\",\n",
    "        \"por\",\n",
    "        \"y\",\n",
    "        \"o\",\n",
    "    ]\n",
    "\n",
    "for p in preposiciones:\n",
    "    nlp.vocab[p].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"necesitar al llenado\"\n",
    "tokens = text.split()\n",
    "for token in nlp(tokens[2]):\n",
    "    print(token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_clean = [x.lower() for x in df.TEXTO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_no_reemplaza_g = [\n",
    "    \"hola\",\n",
    "    \"gracias\",\n",
    "    \"campo\",\n",
    "    \"liga\",\n",
    "    \"bloque\",\n",
    "    \"dato\",\n",
    "    \"archivo\",\n",
    "    \"papa\",\n",
    "    \"mama\",\n",
    "    \"folio\",\n",
    "    \"fecha\",\n",
    "    \"correo\",\n",
    "    \"linea\",\n",
    "    \"apoyo\",\n",
    "    \"sede\",\n",
    "    \"matricula\",\n",
    "    \"nomina\",\n",
    "    \"tesoreria\",\n",
    "    \"pagina\",\n",
    "    \"paa\",\n",
    "    \"paep\",\n",
    "    \"prepa\",\n",
    "    \"secu\",\n",
    "    \"preparatoria\",\n",
    "    \"universidad\",\n",
    "    \"campus\",\n",
    "    \"tec21\",\n",
    "    \"enero\",\n",
    "    \"febrero\",\n",
    "    \"marzo\",\n",
    "    \"abril\",\n",
    "    \"mayo\",\n",
    "    \"junio\",\n",
    "    \"julio\",\n",
    "    \"agosto\",\n",
    "    \"septiembre\",\n",
    "    \"octubre\",\n",
    "    \"noviembre\",\n",
    "    \"diciembre\",\n",
    "    \"sinaloa\",\n",
    "    \"guadalajara\",\n",
    "    \"sonora\",\n",
    "    \"hidalgo\",\n",
    "    \"tampico\",\n",
    "    \"irapuato\",\n",
    "    \"toluca\",\n",
    "    \"aguascalientes\",\n",
    "    \"laguna\",\n",
    "    \"zacatecas\",\n",
    "    \"chiapas\",\n",
    "    \"monterrey\",\n",
    "    \"chihuahua\",\n",
    "    \"puebla\",\n",
    "    \"mexico\",\n",
    "    \"queretaro\",\n",
    "    \"juarez\",\n",
    "    \"saltillo\",\n",
    "    \"morelia\",\n",
    "    \"leon\",\n",
    "    \"veracruz\",\n",
    "    \"obregon\",\n",
    "    \"potosi\",\n",
    "    \"cuernavaca\",\n",
    "    \"santa\",\n",
    "    \"fe\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReemplazaToken(Token, lista_no_reemplaza):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        Token ([type]): [description]\n",
    "        NombresNPArray ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "\n",
    "    # Patron de una matircula o nomina. Ej. A00829621 o l00829621\n",
    "    PatronMatricula = \"([A|a][0-9]{5,8})\"\n",
    "    PatronNomina = \"([L|l][0-9]{5,8})\"\n",
    "\n",
    "    if bool(re.search(PatronMatricula, str(Token.lemma_))):\n",
    "        Temporal = \"zzzmatricula\"\n",
    "    elif str(Token.lemma).lower() == \"no\":\n",
    "        Temporal = \"zzzneg\"\n",
    "    elif (lista_no_reemplaza != None) and (str(Token.text) in lista_no_reemplaza):\n",
    "        Temporal = Token.text\n",
    "    elif str(Token.lemma).lower() == \"mty\":\n",
    "        Temporal = \"monterrey\"\n",
    "    elif str(Token.lemma).lower() == \"gdl\":\n",
    "        Temporal = \"guadalajara\"\n",
    "    elif str(Token.lemma).lower() == \"mex\":\n",
    "        Temporal = \"mexico\"\n",
    "    elif str(Token.text).lower() == \"prepa\":\n",
    "        Temporal = \"preparatoria\"\n",
    "    elif str(Token.text).lower() == \"secu\":\n",
    "        Temporal = \"secundaria\"\n",
    "    elif bool(re.search(PatronNomina, str(Token.lemma_))):\n",
    "        Temporal = \"zzznomina\"\n",
    "    elif Token.like_email:\n",
    "        Temporal = \"zzzemail\"\n",
    "    elif Token.like_url:\n",
    "        Temporal = \"zzzurl\"\n",
    "    elif (Token.pos_ == \"NUM\" or Token.like_num) or (\n",
    "        re.search(r\"(^\\d+$)\", str(Token.lemma_))\n",
    "    ):\n",
    "        Temporal = \"zzznumero\"\n",
    "    else:\n",
    "        Temporal = str(Token.lemma_)\n",
    "        Temporal = Temporal.lower()\n",
    "        Temporal_NFKD = unicodedata.normalize(\"NFKD\", Temporal)\n",
    "        Temporal = \"\".join([c for c in Temporal_NFKD if not unicodedata.combining(c)])\n",
    "        if re.search(r\"zzz\", Temporal):\n",
    "            Temporal = Temporal\n",
    "        else:\n",
    "            Temporal = re.sub(r\"[^a-zA-Z]+\", \"\", Temporal)\n",
    "\n",
    "    return Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lematiza_menu(doc):\n",
    "    doc_tokens = doc.split()\n",
    "    LemmasList = []\n",
    "    for tok in doc_tokens:\n",
    "        for Token in nlp(tok):\n",
    "            Temporal = \"\"\n",
    "            if Token.text == \"?\":\n",
    "                HuboPregunta = True\n",
    "            if not Token.is_stop:\n",
    "                if Token.text in lista_no_reemplaza_g:\n",
    "                    Token.lemma_ == Token.text\n",
    "                    Temporal = ReemplazaToken(\n",
    "                        Token, lista_no_reemplaza_g\n",
    "                    )\n",
    "                else:\n",
    "                    Temporal = ReemplazaToken(\n",
    "                        Token, lista_no_reemplaza_g\n",
    "                    )\n",
    "            if ((Temporal not in string.punctuation)) and (\n",
    "                re.match(\"([a-zA-Z0-9]+)\", Temporal) != None\n",
    "            ):\n",
    "                LemmasList.append(Temporal)\n",
    "\n",
    "    doc = \" \".join(LemmasList)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OracionLematizada'] = [lematiza_menu(x) for x in df.TEXTO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"modified-menus.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}